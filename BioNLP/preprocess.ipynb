{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import nltk.data\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentence_list(text_file):\n",
    "    sentence_list = []\n",
    "    with open(text_file,'r') as reader:\n",
    "        for i,line in enumerate(reader):\n",
    "            temp_list = tokenizer.tokenize(line.strip())\n",
    "            sentence_list.extend(temp_list)  \n",
    "    return sentence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_dict(a1_file):\n",
    "    entity_dict={}\n",
    "    with open(a1_file, 'r') as reader:\n",
    "        for line in reader:\n",
    "            tab_del_list=line.strip().split(\"\\t\")\n",
    "            entity_id = tab_del_list[0]\n",
    "            entity_type = tab_del_list[1].split(' ')[0]\n",
    "            start_off = int(tab_del_list[1].split(' ')[1])\n",
    "            end_off = int(tab_del_list[1].split(' ')[2])\n",
    "            entity_name = tab_del_list[2]\n",
    "            \n",
    "            #print entity_id, entity_type,start_off, end_off,entity_name\n",
    "            if entity_id not in entity_dict:\n",
    "                entity_dict[entity_id] = [entity_type, start_off, end_off,entity_name]\n",
    "            elif entity_id in entity_dict:\n",
    "                raise Exception('key error')\n",
    "                \n",
    "    return entity_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_entity_set(a1_file):\n",
    "    with open(a1_file ,'r') as reader:\n",
    "        entity_set = set([line.strip().split('\\t')[2] for line in reader])\n",
    "    return entity_set\n",
    "\n",
    "def get_event_dict(a2_file):\n",
    "    event_dict={}\n",
    "    with open(a2_file, 'r') as reader:\n",
    "        for line in reader:\n",
    "            if 'E' in line.strip().split('\\t')[0]:\n",
    "                event_id = line.strip().split('\\t')[0]\n",
    "                if event_id not in event_dict:\n",
    "                    event_dict[event_id]=line.strip().split('\\t')[1].split(' ')\n",
    "                else:\n",
    "                    raise Exception('key error')  \n",
    "\n",
    "                \n",
    "    return event_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_entity_relation_triple(line, event_dict, entity_dict):\n",
    "    if 'E' in line.split('\\t')[0]:\n",
    "        #print line.split('\\t')[0],line.split('\\t')[1].split(' ')\n",
    "        if len(line.split('\\t')[1].split(' '))>=3:\n",
    "            theme_string = line.split('\\t')[1].split(' ')[1].split(':')[1]\n",
    "            cause_string = line.split('\\t')[1].split(' ')[2].split(':')[1]\n",
    "            \n",
    "            #print line\n",
    "            if 'E' in theme_string:\n",
    "                effect = event_dict[theme_string][0].split(':')[0]\n",
    "                result_entity_id = event_dict[theme_string][1].split(':')[1]\n",
    "\n",
    "                if 'E' in cause_string:\n",
    "                    cause_entity_id = event_dict[cause_string][1].split(':')[1]\n",
    "                    if 'T' in cause_entity_id and 'T' in result_entity_id:\n",
    "                        return entity_dict[cause_entity_id][3] , effect ,  entity_dict[result_entity_id][3]\n",
    "                \n",
    "                elif 'E' not in cause_string :\n",
    "                    cause_entity_id = line.split('\\t')[1].split(' ')[2].split(':')[1]\n",
    "                    if 'T' in result_entity_id:\n",
    "                        return entity_dict[cause_entity_id][3] , effect , entity_dict[result_entity_id][3]\n",
    "\n",
    "            elif 'E' in cause_string:\n",
    "                    effect = line.split('\\t')[1].split(' ')[0].split(':')[0]\n",
    "                    result_entity_id = theme_string\n",
    "                    cause_entity_id = event_dict[cause_string][1].split(':')[1]\n",
    "                    \n",
    "                    if 'T' in cause_entity_id: \n",
    "                        return entity_dict[cause_entity_id][3] , effect , entity_dict[result_entity_id][3]\n",
    "\n",
    "\n",
    "def extract_entity_relation_triple_in_a2_file(a2_file,event_dict,entity_dict):\n",
    "    result_list =[]\n",
    "    \n",
    "    with open(a2_file, 'r') as reader:\n",
    "        for line in reader:\n",
    "            line = line.strip()\n",
    "            result = extract_entity_relation_triple(line,event_dict,entity_dict)\n",
    "            if result is not None:\n",
    "                result_list.append(result)\n",
    "                \n",
    "    return result_list\n",
    "             \n",
    "    \n",
    "\n",
    "def annotate(text, relation_triple_list,outputpath):\n",
    "    fw = open(outputpath,'a')\n",
    "    \n",
    "    sentence_list = get_sentence_list(text)\n",
    "    for sentence in sentence_list:    \n",
    "        sentence_contain_triple_list = []\n",
    "        for relation_triple in list(set(relation_triple_list)):\n",
    "            if (relation_triple[0] in sentence) and (relation_triple[2] in sentence):\n",
    "                if (relation_triple[0] == relation_triple[2]):\n",
    "                    if sentence.count(relation_triple[0])>=2:\n",
    "                        sentence_contain_triple_list.append(relation_triple)\n",
    "                else:\n",
    "                    sentence_contain_triple_list.append(relation_triple)\n",
    "        \n",
    "        if len(sentence_contain_triple_list)>=1:\n",
    "            fw.write(sentence+'\\n')\n",
    "            last_index = len(sentence_contain_triple_list)-1\n",
    "            for i,triple in enumerate(sentence_contain_triple_list):\n",
    "                if i!= last_index:\n",
    "                    fw.write(str(triple)+',')\n",
    "                elif i==last_index:\n",
    "                    fw.write(str(triple)+'\\n')\n",
    "            fw.write('\\n')\n",
    "\n",
    "            \n",
    "            \n",
    "    fw.close()\n",
    "                \n",
    "def preprocess(text, a1_file, a2_file,outputpath):\n",
    "    entity_dict = get_entity_dict(a1_file)\n",
    "    event_dict = get_event_dict(a2_file)\n",
    "    entity_relation_triple_list = extract_entity_relation_triple_in_a2_file(a2_file,event_dict,entity_dict)\n",
    "    annotate(text,entity_relation_triple_list,outputpath)\n",
    "    \n",
    "    return entity_relation_triple_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text = './data/BioNLP-ST-2013_GE_train_data_rev3/PMC-2889865-06-Discussion.txt'\n",
    "a1 = './data/BioNLP-ST-2013_GE_train_data_rev3/PMC-2889865-06-Discussion.a1'\n",
    "a2 = './data/BioNLP-ST-2013_GE_train_data_rev3/PMC-2889865-06-Discussion.a2'\n",
    "outputpath=\"Total_output.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('IL-2', 'Gene_expression', 'IL-2'),\n",
       " ('IL-2', 'Localization', 'IL-2'),\n",
       " ('Bcl10', 'Protein_catabolism', 'Bcl10')]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(text,a1, a2 ,\"temp.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_folder = './data/Total/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_list = list(set(map(lambda x:x.split('.')[0],os.listdir(dataset_folder))))\n",
    "if 'LICENSE' in file_list:\n",
    "    file_list.remove('LICENSE')\n",
    "if 'README' in file_list:\n",
    "    file_list.remove('README')\n",
    "path_list = map(lambda x:dataset_folder+x ,file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_list=[]\n",
    "for path in path_list:\n",
    "    text = path+'.txt'\n",
    "    a1_file = path+'.a1'\n",
    "    a2_file = path+'.a2'\n",
    "    total_list.extend(preprocess(text,a1_file, a2_file,outputpath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count =0\n",
    "with open(outputpath,'r') as reader:\n",
    "    for i,line in enumerate(reader):\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3870"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
